{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 785 files belonging to 5 classes.\n",
      "Using 550 files for training.\n",
      "Found 785 files belonging to 5 classes.\n",
      "Using 235 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 16\n",
    "img_width = 8\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Dataset\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Dataset\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "    \n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16078432 0.9803922\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(120, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 1.1793 - accuracy: 0.5291 - val_loss: 0.9134 - val_accuracy: 0.6723\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7882 - accuracy: 0.7800 - val_loss: 0.6870 - val_accuracy: 0.8596\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.8818 - val_loss: 0.5010 - val_accuracy: 0.9021\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.9309 - val_loss: 0.3764 - val_accuracy: 0.9234\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.9527 - val_loss: 0.2964 - val_accuracy: 0.9319\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9582 - val_loss: 0.2567 - val_accuracy: 0.9447\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9618 - val_loss: 0.2368 - val_accuracy: 0.9447\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9655 - val_loss: 0.2215 - val_accuracy: 0.9489\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9655 - val_loss: 0.2128 - val_accuracy: 0.9489\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9673 - val_loss: 0.2075 - val_accuracy: 0.9489\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9673 - val_loss: 0.2022 - val_accuracy: 0.9489\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9673 - val_loss: 0.1988 - val_accuracy: 0.9489\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9673 - val_loss: 0.1909 - val_accuracy: 0.9489\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.9673 - val_loss: 0.1880 - val_accuracy: 0.9489\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9673 - val_loss: 0.1831 - val_accuracy: 0.9489\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9673 - val_loss: 0.1762 - val_accuracy: 0.9489\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9673 - val_loss: 0.1694 - val_accuracy: 0.9489\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9673 - val_loss: 0.1621 - val_accuracy: 0.9489\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9673 - val_loss: 0.1552 - val_accuracy: 0.9489\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9673 - val_loss: 0.1464 - val_accuracy: 0.9489\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9673 - val_loss: 0.1369 - val_accuracy: 0.9489\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9673 - val_loss: 0.1263 - val_accuracy: 0.9489\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9691 - val_loss: 0.1178 - val_accuracy: 0.9660\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9709 - val_loss: 0.1054 - val_accuracy: 0.9660\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9709 - val_loss: 0.0985 - val_accuracy: 0.9660\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9727 - val_loss: 0.0866 - val_accuracy: 0.9660\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9727 - val_loss: 0.0791 - val_accuracy: 0.9660\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9800 - val_loss: 0.0662 - val_accuracy: 0.9660\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.0593 - val_accuracy: 0.9660\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 0.0501 - val_accuracy: 0.9660\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9964 - val_loss: 0.0439 - val_accuracy: 0.9660\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9964 - val_loss: 0.0397 - val_accuracy: 0.9660\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9982 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.7195e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.4657e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.9698e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7231e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.3819e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.2715e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.8820e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.6967e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.4803e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.1367e-04 - accuracy: 1.0000 - val_loss: 9.4748e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9742e-04 - accuracy: 1.0000 - val_loss: 9.4476e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.7338e-04 - accuracy: 1.0000 - val_loss: 9.0658e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.5153e-04 - accuracy: 1.0000 - val_loss: 9.1062e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3476e-04 - accuracy: 1.0000 - val_loss: 8.5142e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1947e-04 - accuracy: 1.0000 - val_loss: 8.4760e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9911e-04 - accuracy: 1.0000 - val_loss: 8.2130e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7891e-04 - accuracy: 1.0000 - val_loss: 8.0723e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6848e-04 - accuracy: 1.0000 - val_loss: 7.6764e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5060e-04 - accuracy: 1.0000 - val_loss: 7.7697e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3243e-04 - accuracy: 1.0000 - val_loss: 7.2458e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2024e-04 - accuracy: 1.0000 - val_loss: 7.3206e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0754e-04 - accuracy: 1.0000 - val_loss: 6.9599e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9283e-04 - accuracy: 1.0000 - val_loss: 6.9145e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7874e-04 - accuracy: 1.0000 - val_loss: 6.6483e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6741e-04 - accuracy: 1.0000 - val_loss: 6.7283e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5448e-04 - accuracy: 1.0000 - val_loss: 6.2188e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4548e-04 - accuracy: 1.0000 - val_loss: 6.3644e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3247e-04 - accuracy: 1.0000 - val_loss: 5.9397e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.2411e-04 - accuracy: 1.0000 - val_loss: 5.9656e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1013e-04 - accuracy: 1.0000 - val_loss: 5.6417e-04 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0383e-04 - accuracy: 1.0000 - val_loss: 5.7668e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.9088e-04 - accuracy: 1.0000 - val_loss: 5.2501e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.8476e-04 - accuracy: 1.0000 - val_loss: 5.5402e-04 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.6873e-04 - accuracy: 1.0000 - val_loss: 5.0035e-04 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6564e-04 - accuracy: 1.0000 - val_loss: 5.2784e-04 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.5006e-04 - accuracy: 1.0000 - val_loss: 4.8990e-04 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5115e-04 - accuracy: 1.0000 - val_loss: 5.1846e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.3873e-04 - accuracy: 1.0000 - val_loss: 4.6182e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.3518e-04 - accuracy: 1.0000 - val_loss: 4.8012e-04 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2061e-04 - accuracy: 1.0000 - val_loss: 4.4581e-04 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1813e-04 - accuracy: 1.0000 - val_loss: 4.6827e-04 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.0777e-04 - accuracy: 1.0000 - val_loss: 4.2893e-04 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.0583e-04 - accuracy: 1.0000 - val_loss: 4.5006e-04 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9452e-04 - accuracy: 1.0000 - val_loss: 4.0662e-04 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9171e-04 - accuracy: 1.0000 - val_loss: 4.2807e-04 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8034e-04 - accuracy: 1.0000 - val_loss: 3.9983e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8099e-04 - accuracy: 1.0000 - val_loss: 4.1397e-04 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6998e-04 - accuracy: 1.0000 - val_loss: 3.7792e-04 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6792e-04 - accuracy: 1.0000 - val_loss: 4.0092e-04 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5956e-04 - accuracy: 1.0000 - val_loss: 3.6286e-04 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5847e-04 - accuracy: 1.0000 - val_loss: 3.8250e-04 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4814e-04 - accuracy: 1.0000 - val_loss: 3.5543e-04 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4588e-04 - accuracy: 1.0000 - val_loss: 3.6804e-04 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3878e-04 - accuracy: 1.0000 - val_loss: 3.4310e-04 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3689e-04 - accuracy: 1.0000 - val_loss: 3.5382e-04 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2983e-04 - accuracy: 1.0000 - val_loss: 3.2608e-04 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2701e-04 - accuracy: 1.0000 - val_loss: 3.4209e-04 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2073e-04 - accuracy: 1.0000 - val_loss: 3.1900e-04 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1768e-04 - accuracy: 1.0000 - val_loss: 3.2616e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1281e-04 - accuracy: 1.0000 - val_loss: 3.1403e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1175e-04 - accuracy: 1.0000 - val_loss: 3.2137e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0488e-04 - accuracy: 1.0000 - val_loss: 2.8960e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 3.0537e-04 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9575e-04 - accuracy: 1.0000 - val_loss: 2.9004e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9579e-04 - accuracy: 1.0000 - val_loss: 2.9459e-04 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9005e-04 - accuracy: 1.0000 - val_loss: 2.7376e-04 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8806e-04 - accuracy: 1.0000 - val_loss: 2.8038e-04 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8159e-04 - accuracy: 1.0000 - val_loss: 2.6516e-04 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8064e-04 - accuracy: 1.0000 - val_loss: 2.7462e-04 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7582e-04 - accuracy: 1.0000 - val_loss: 2.5987e-04 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7513e-04 - accuracy: 1.0000 - val_loss: 2.6764e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6863e-04 - accuracy: 1.0000 - val_loss: 2.4903e-04 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6846e-04 - accuracy: 1.0000 - val_loss: 2.5181e-04 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6266e-04 - accuracy: 1.0000 - val_loss: 2.4185e-04 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 2.4130e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5764e-04 - accuracy: 1.0000 - val_loss: 2.3569e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5564e-04 - accuracy: 1.0000 - val_loss: 2.3748e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5172e-04 - accuracy: 1.0000 - val_loss: 2.2602e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 2.2768e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4710e-04 - accuracy: 1.0000 - val_loss: 2.2350e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4503e-04 - accuracy: 1.0000 - val_loss: 2.2384e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4327e-04 - accuracy: 1.0000 - val_loss: 2.1777e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4040e-04 - accuracy: 1.0000 - val_loss: 2.1976e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3841e-04 - accuracy: 1.0000 - val_loss: 2.1076e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3549e-04 - accuracy: 1.0000 - val_loss: 2.1340e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3527e-04 - accuracy: 1.0000 - val_loss: 2.0663e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3094e-04 - accuracy: 1.0000 - val_loss: 1.9887e-04 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2892e-04 - accuracy: 1.0000 - val_loss: 2.0047e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2598e-04 - accuracy: 1.0000 - val_loss: 1.9633e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2625e-04 - accuracy: 1.0000 - val_loss: 1.9877e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2282e-04 - accuracy: 1.0000 - val_loss: 1.8744e-04 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2161e-04 - accuracy: 1.0000 - val_loss: 1.9122e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1844e-04 - accuracy: 1.0000 - val_loss: 1.8338e-04 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1792e-04 - accuracy: 1.0000 - val_loss: 1.8568e-04 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1474e-04 - accuracy: 1.0000 - val_loss: 1.7667e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1413e-04 - accuracy: 1.0000 - val_loss: 1.7898e-04 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1044e-04 - accuracy: 1.0000 - val_loss: 1.7192e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1057e-04 - accuracy: 1.0000 - val_loss: 1.7477e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0695e-04 - accuracy: 1.0000 - val_loss: 1.6992e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0718e-04 - accuracy: 1.0000 - val_loss: 1.6873e-04 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 1.6165e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0296e-04 - accuracy: 1.0000 - val_loss: 1.6430e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0142e-04 - accuracy: 1.0000 - val_loss: 1.5880e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.9833e-05 - accuracy: 1.0000 - val_loss: 1.5739e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.8164e-05 - accuracy: 1.0000 - val_loss: 1.5266e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.6527e-05 - accuracy: 1.0000 - val_loss: 1.5460e-04 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.5053e-05 - accuracy: 1.0000 - val_loss: 1.5010e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.3853e-05 - accuracy: 1.0000 - val_loss: 1.5102e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.2423e-05 - accuracy: 1.0000 - val_loss: 1.4383e-04 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.0798e-05 - accuracy: 1.0000 - val_loss: 1.4730e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.9278e-05 - accuracy: 1.0000 - val_loss: 1.4126e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.8392e-05 - accuracy: 1.0000 - val_loss: 1.4205e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.6724e-05 - accuracy: 1.0000 - val_loss: 1.3567e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.5474e-05 - accuracy: 1.0000 - val_loss: 1.3898e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.4389e-05 - accuracy: 1.0000 - val_loss: 1.3217e-04 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.2951e-05 - accuracy: 1.0000 - val_loss: 1.3428e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.1664e-05 - accuracy: 1.0000 - val_loss: 1.3023e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.0561e-05 - accuracy: 1.0000 - val_loss: 1.3088e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.9345e-05 - accuracy: 1.0000 - val_loss: 1.2725e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.8049e-05 - accuracy: 1.0000 - val_loss: 1.2670e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.7254e-05 - accuracy: 1.0000 - val_loss: 1.2524e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.5956e-05 - accuracy: 1.0000 - val_loss: 1.2144e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.4885e-05 - accuracy: 1.0000 - val_loss: 1.1961e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.3573e-05 - accuracy: 1.0000 - val_loss: 1.2028e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.2480e-05 - accuracy: 1.0000 - val_loss: 1.1640e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.1414e-05 - accuracy: 1.0000 - val_loss: 1.1847e-04 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.0808e-05 - accuracy: 1.0000 - val_loss: 1.1367e-04 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9325e-05 - accuracy: 1.0000 - val_loss: 1.1123e-04 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7866e-05 - accuracy: 1.0000 - val_loss: 1.0930e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6577e-05 - accuracy: 1.0000 - val_loss: 1.0931e-04 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5864e-05 - accuracy: 1.0000 - val_loss: 1.0615e-04 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4464e-05 - accuracy: 1.0000 - val_loss: 1.0353e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3230e-05 - accuracy: 1.0000 - val_loss: 1.0293e-04 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1712e-05 - accuracy: 1.0000 - val_loss: 1.0233e-04 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1414e-05 - accuracy: 1.0000 - val_loss: 1.0029e-04 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0364e-05 - accuracy: 1.0000 - val_loss: 9.8750e-05 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9416e-05 - accuracy: 1.0000 - val_loss: 9.8680e-05 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8203e-05 - accuracy: 1.0000 - val_loss: 9.4285e-05 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7473e-05 - accuracy: 1.0000 - val_loss: 9.5447e-05 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6118e-05 - accuracy: 1.0000 - val_loss: 9.2351e-05 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5341e-05 - accuracy: 1.0000 - val_loss: 9.1270e-05 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3901e-05 - accuracy: 1.0000 - val_loss: 1.0134e-04 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0081e-05 - accuracy: 1.0000 - val_loss: 7.1108e-05 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8851e-05 - accuracy: 1.0000 - val_loss: 8.0241e-05 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6602e-05 - accuracy: 1.0000 - val_loss: 6.1653e-05 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6181e-05 - accuracy: 1.0000 - val_loss: 7.6970e-05 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4173e-05 - accuracy: 1.0000 - val_loss: 5.8794e-05 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3273e-05 - accuracy: 1.0000 - val_loss: 6.5511e-05 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1932e-05 - accuracy: 1.0000 - val_loss: 5.3840e-05 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.1478e-05 - accuracy: 1.0000 - val_loss: 6.4233e-05 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0625e-05 - accuracy: 1.0000 - val_loss: 5.0601e-05 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.9350e-05 - accuracy: 1.0000 - val_loss: 5.9652e-05 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.8929e-05 - accuracy: 1.0000 - val_loss: 4.8077e-05 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.7905e-05 - accuracy: 1.0000 - val_loss: 5.6310e-05 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.7665e-05 - accuracy: 1.0000 - val_loss: 4.6638e-05 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6210e-05 - accuracy: 1.0000 - val_loss: 5.1159e-05 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.5776e-05 - accuracy: 1.0000 - val_loss: 4.5313e-05 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.4853e-05 - accuracy: 1.0000 - val_loss: 4.8729e-05 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.4994e-05 - accuracy: 1.0000 - val_loss: 4.2499e-05 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.3633e-05 - accuracy: 1.0000 - val_loss: 4.4553e-05 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.3123e-05 - accuracy: 1.0000 - val_loss: 4.1355e-05 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2552e-05 - accuracy: 1.0000 - val_loss: 4.4445e-05 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.2638e-05 - accuracy: 1.0000 - val_loss: 3.9120e-05 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1489e-05 - accuracy: 1.0000 - val_loss: 4.0431e-05 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1001e-05 - accuracy: 1.0000 - val_loss: 3.8000e-05 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.0301e-05 - accuracy: 1.0000 - val_loss: 3.8823e-05 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.9863e-05 - accuracy: 1.0000 - val_loss: 3.6766e-05 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9339e-05 - accuracy: 1.0000 - val_loss: 3.7322e-05 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8862e-05 - accuracy: 1.0000 - val_loss: 3.5030e-05 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8442e-05 - accuracy: 1.0000 - val_loss: 3.6534e-05 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8031e-05 - accuracy: 1.0000 - val_loss: 3.3957e-05 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.7543e-05 - accuracy: 1.0000 - val_loss: 3.5259e-05 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.7109e-05 - accuracy: 1.0000 - val_loss: 3.4663e-05 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6915e-05 - accuracy: 1.0000 - val_loss: 3.3788e-05 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6387e-05 - accuracy: 1.0000 - val_loss: 3.4021e-05 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6180e-05 - accuracy: 1.0000 - val_loss: 3.1064e-05 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5470e-05 - accuracy: 1.0000 - val_loss: 3.2662e-05 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5382e-05 - accuracy: 1.0000 - val_loss: 3.0673e-05 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4867e-05 - accuracy: 1.0000 - val_loss: 3.1013e-05 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4535e-05 - accuracy: 1.0000 - val_loss: 2.9845e-05 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4283e-05 - accuracy: 1.0000 - val_loss: 2.9627e-05 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3676e-05 - accuracy: 1.0000 - val_loss: 2.9538e-05 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.3686e-05 - accuracy: 1.0000 - val_loss: 2.7876e-05 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2902e-05 - accuracy: 1.0000 - val_loss: 2.7677e-05 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2845e-05 - accuracy: 1.0000 - val_loss: 2.7864e-05 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2417e-05 - accuracy: 1.0000 - val_loss: 2.7635e-05 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2385e-05 - accuracy: 1.0000 - val_loss: 2.6057e-05 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1666e-05 - accuracy: 1.0000 - val_loss: 2.6251e-05 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1515e-05 - accuracy: 1.0000 - val_loss: 2.6051e-05 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1242e-05 - accuracy: 1.0000 - val_loss: 2.4874e-05 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0756e-05 - accuracy: 1.0000 - val_loss: 2.5436e-05 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0676e-05 - accuracy: 1.0000 - val_loss: 2.5108e-05 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0344e-05 - accuracy: 1.0000 - val_loss: 2.4069e-05 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 3.0644e-05 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-d51a09ef67c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
