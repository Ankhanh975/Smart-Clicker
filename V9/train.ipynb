{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6598 files belonging to 42 classes.\n",
      "Using 4619 files for training.\n",
      "Found 6598 files belonging to 42 classes.\n",
      "Using 1979 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 16\n",
    "img_width = 8\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Dataset\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=256,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Dataset\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=256,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "    \n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1764706 0.9843138\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(\"Dataset\"))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(75, activation='relu'),\n",
    "  # tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=5*1e-6)\n",
    "# model.compile(optimizer=opt, \n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import random\n",
    "NAME = \"basic\"+str(random.randint(1,1000))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "# cd \"C:\\src\\Python\\Smart Clicker\\V9\\\"\n",
    "# tensorboard --logdir=\"logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "145/145 [==============================] - 8s 51ms/step - loss: 2.6297 - accuracy: 0.4025 - val_loss: 1.4022 - val_accuracy: 0.6387\n",
      "Epoch 2/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.9346 - accuracy: 0.7623 - val_loss: 0.6886 - val_accuracy: 0.8044\n",
      "Epoch 3/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8461 - val_loss: 0.4370 - val_accuracy: 0.8919\n",
      "Epoch 4/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8950 - val_loss: 0.3139 - val_accuracy: 0.9040\n",
      "Epoch 5/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9253 - val_loss: 0.2457 - val_accuracy: 0.9050\n",
      "Epoch 6/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9465 - val_loss: 0.1934 - val_accuracy: 0.9232\n",
      "Epoch 7/50\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9584 - val_loss: 0.1521 - val_accuracy: 0.9409\n",
      "Epoch 8/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9649 - val_loss: 0.1235 - val_accuracy: 0.9707\n",
      "Epoch 9/50\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 0.1161 - accuracy: 0.9695 - val_loss: 0.1075 - val_accuracy: 0.9778\n",
      "Epoch 10/50\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 0.1016 - accuracy: 0.9727 - val_loss: 0.0980 - val_accuracy: 0.9813\n",
      "Epoch 11/50\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 0.0910 - accuracy: 0.9751 - val_loss: 0.0898 - val_accuracy: 0.9843\n",
      "Epoch 12/50\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9773 - val_loss: 0.0816 - val_accuracy: 0.9874\n",
      "Epoch 13/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9792 - val_loss: 0.0737 - val_accuracy: 0.9884\n",
      "Epoch 14/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9829 - val_loss: 0.0603 - val_accuracy: 0.9904\n",
      "Epoch 15/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9848 - val_loss: 0.0539 - val_accuracy: 0.9899\n",
      "Epoch 16/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9868 - val_loss: 0.0492 - val_accuracy: 0.9899\n",
      "Epoch 17/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9892 - val_loss: 0.0423 - val_accuracy: 0.9904\n",
      "Epoch 18/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9894 - val_loss: 0.0369 - val_accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.0328 - val_accuracy: 0.9949\n",
      "Epoch 20/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9924 - val_loss: 0.0289 - val_accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.0256 - val_accuracy: 0.9949\n",
      "Epoch 22/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0243 - val_accuracy: 0.9949\n",
      "Epoch 23/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9949\n",
      "Epoch 24/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.0199 - val_accuracy: 0.9949\n",
      "Epoch 25/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.0159 - val_accuracy: 0.9965\n",
      "Epoch 26/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
      "Epoch 27/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.0157 - val_accuracy: 0.9939\n",
      "Epoch 28/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0125 - val_accuracy: 0.9960\n",
      "Epoch 29/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 31/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9812 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 40/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0191 - val_accuracy: 0.9934\n",
      "Epoch 45/50\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9890 - val_loss: 0.0047 - val_accuracy: 0.9995\n",
      "Epoch 48/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9844 - val_loss: 0.0166 - val_accuracy: 0.9939\n",
      "Epoch 50/50\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db35cad8c8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50, callbacks=[tensorboard]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"item_reader_seq.model\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 37\n",
      "19 19\n",
      "20 20\n",
      "39 39\n",
      "26 26\n",
      "11 11\n",
      "23 23\n",
      "28 28\n",
      "11 11\n",
      "3 3\n",
      "31 31\n",
      "1 1\n",
      "40 40\n",
      "33 33\n",
      "32 32\n",
      "39 39\n",
      "23 23\n",
      "27 27\n",
      "9 9\n",
      "21 21\n",
      "39 39\n",
      "21 21\n",
      "31 31\n",
      "19 19\n",
      "40 40\n",
      "17 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-99a0874836f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# print(y_predict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for index, batch in enumerate(val_ds):\n",
    "    X, y = batch\n",
    "    X = X.numpy()\n",
    "    y = y.numpy()\n",
    "    \n",
    "    y_predict = model.predict(X)\n",
    "    y_predict = np.argmax(y_predict, axis=1)\n",
    "    # for i in range(32):\n",
    "    #     if y[i]!=y_predict[i]:\n",
    "    #         print(index, i)\n",
    "    #         cv2.imwrite(f\"{random.randint(1, 100)}.png\", X[i])\n",
    "    \n",
    "    cv2.imshow('image', X[0]) \n",
    "    cv2.imwrite(\"image.png\", cv2.cvtColor(X[0], cv2.COLOR_RGB2BGR))\n",
    "    cv2.waitKey(0)\n",
    "    print(y[0], y_predict[0])\n",
    "    # print(y_predict)\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 27, 27, 11, 27, 27, 27, 27, 27,  7, 27, 27, 27, 27, 27, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 34,  8, 10,  9, 13, 14,\n",
       "       15, 16], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need Bandicam to take a screenshot when Minecraft in full screen mode\n",
    "Z = [(4, 4), (4, 76), (4, 148), (4, 220), (4, 292),\n",
    "    (4, 364), (4, 436), (4, 508), (4, 580), (76, 4),\n",
    "    (76, 76), (76, 148), (76, 220), (76, 292), (76, 364),\n",
    "    (76, 436), (76, 508), (76, 580), (148, 4), (148, 76),\n",
    "    (148, 148), (148, 220), (148, 292), (148, 364), (148, 436),\n",
    "    (148, 508), (148, 580), (236, 4), (236, 76), (236, 148),\n",
    "    (236, 220), (236, 292), (236, 364), (236, 436), (236, 508),\n",
    "    (236, 580)]\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"item_reader_seq.model\")\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "img = cv2.imread(\"D:/Bi/Record/javaw 2021-11-05 21-41-48-099.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "img = img[540:845, 636:1285]\n",
    "# img = img[480:845, 600:1285]\n",
    "\n",
    "Slot = []\n",
    "for x, y in Z:\n",
    "    Slot.append(img[x:x+64, y:y+32])\n",
    "    # Slot.append(img)\n",
    "\n",
    "for n in range(36):\n",
    "    Slot[n] = cv2.resize(Slot[n], (32//4, 64//4), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# model([Slot,], training=False)\n",
    "# x=np.array(Slot)\n",
    "x=model.predict(np.array(Slot))\n",
    "# .numpy()\n",
    "x = np.argmax(x, axis=1)\n",
    "\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
